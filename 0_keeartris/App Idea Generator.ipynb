{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7774d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "from typing import Tuple\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df780140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b79b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show key prefixes (optional sanity check)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "for name, value in [\n",
    "    (\"OpenAI\", openai_api_key),\n",
    "    (\"Anthropic\", anthropic_api_key),\n",
    "    (\"Google\", google_api_key),\n",
    "    (\"DeepSeek\", deepseek_api_key),\n",
    "    (\"Groq\", groq_api_key),\n",
    "]:\n",
    "    if value:\n",
    "        print(f\"{name} API Key exists and begins {value[:8]}\")\n",
    "    else:\n",
    "        print(f\"{name} API Key not set (optional for some)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ea7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base idea prompt\n",
    "base_prompt = \"\"\"\n",
    "Please come up with an idea for an app that I can build using Agentic AI.\n",
    "The idea must:\n",
    "- Be buildable for Android, iPhone, and Web\n",
    "- Be highly profitable and easy to monetize\n",
    "- Attract a niche but abundant audience\n",
    "- Avoid heavy custom back-end systems (prefer existing APIs)\n",
    "- Avoid complex legal/regulatory exposure\n",
    "\n",
    "Return only the idea plus concise arguments for how it meets each criterion.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "openai_client = OpenAI()\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gpt-5-mini\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": base_prompt}]\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=messages )\n",
    "\n",
    "answers = []\n",
    "answer = response.choices[0].message.content\n",
    "answers.append(answer)\n",
    "\n",
    "def build_qa_prompt(idea: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are evaluating an app idea. Score each of the following criteria 0 or 1 (integer only):\n",
    "1) clarity\n",
    "2) accuracy\n",
    "3) strength of arguments\n",
    "4) can be built entirely using Agentic AI\n",
    "5) can be built on Android, Web, and iPhone\n",
    "6) highly profitable\n",
    "7) attracts a niche but abundant audience\n",
    "8) easy to monetize\n",
    "9) avoids custom extensive back-end systems; can rely on existing APIs\n",
    "10) avoids overly complex legal/regulatory clearance\n",
    "\n",
    "Return JSON only, with schema: {{\"results\": [\"<total_score_0-10>\", \"<failed criteria or 'Met all criteria'>\"]}}.\n",
    "Keep the second field short (<= 60 words). No markdown, no extra text.\n",
    "\n",
    "Idea to evaluate:\n",
    "{idea}\n",
    "\"\"\"\n",
    "\n",
    "def parse_qa_response(text: str) -> Tuple[int, str]:\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "        results = data.get(\"results\") or []\n",
    "        score_raw = results[0] if len(results) > 0 else None\n",
    "        feedback = results[1] if len(results) > 1 else \"\"\n",
    "        score = int(str(score_raw))\n",
    "        return score, str(feedback)\n",
    "    except Exception as exc:\n",
    "        # On parse failure, treat as zero score and pass raw text back\n",
    "        return 0, f\"QA parse error: {exc}; raw: {text}\"\n",
    "\n",
    "def generate_idea(prompt: str) -> str:\n",
    "    resp = openai_client.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "def evaluate_idea(idea: str) -> Tuple[int, str, str]:\n",
    "    qa_prompt = build_qa_prompt(idea)\n",
    "    resp = gemini.chat.completions.create(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        messages=[{\"role\": \"user\", \"content\": qa_prompt}],\n",
    "    )\n",
    "    qa_text = resp.choices[0].message.content\n",
    "    score, feedback = parse_qa_response(qa_text)\n",
    "    return score, feedback, qa_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec862bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refinement loop: iterate until score == 10 or 10 iterations reached\n",
    "max_iterations = 10\n",
    "prompt_for_idea = base_prompt\n",
    "idea_history = []\n",
    "qa_history = []\n",
    "best_idea = None\n",
    "best_score = -1\n",
    "\n",
    "for i in range(1, max_iterations + 1):\n",
    "    print(f\"--- Iteration {i} ---\")\n",
    "    idea = generate_idea(prompt_for_idea)\n",
    "    print(\"Idea:\", idea)\n",
    "\n",
    "    score, feedback, raw_qa = evaluate_idea(idea)\n",
    "    print(f\"QA score: {score}\")\n",
    "    print(f\"QA feedback: {feedback}\")\n",
    "\n",
    "    idea_history.append(idea)\n",
    "    qa_history.append({\"iteration\": i, \"score\": score, \"feedback\": feedback, \"raw\": raw_qa})\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_idea = idea\n",
    "\n",
    "    if score == 10:\n",
    "        print(\"Perfect score reached. Stopping.\")\n",
    "        break\n",
    "\n",
    "    # Prepare next prompt using feedback\n",
    "    prompt_for_idea = base_prompt + f\"Improve the previous idea using this QA feedback (fix deficiencies without bloating scope): {feedback} Return only the revised idea plus concise arguments.\"\n",
    "\n",
    "print(\"=== Summary ===\")\n",
    "print(f\"Best score: {best_score}\")\n",
    "print(\"Best idea:\", best_idea)\n",
    "print(\"QA trail:\")\n",
    "for entry in qa_history:\n",
    "    print(f\"Iter {entry['iteration']}: score={entry['score']} feedback={entry['feedback']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f178e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(best_idea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(qa_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8b51e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
